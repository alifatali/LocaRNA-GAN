{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfae9982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ k-mer features extracted: (12410, 64) (samples x 64 features)\n",
      "📝 Saved: X_kmer_temp.npy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# بارگذاری داده‌ها\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "# استخراج k-mer با k=3\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3), lowercase=False)\n",
    "kmer_features = vectorizer.fit_transform(sequences)\n",
    "\n",
    "# تبدیل به آرایه NumPy\n",
    "X_kmer = kmer_features.toarray()\n",
    "\n",
    "print(f\"✅ k-mer features extracted: {X_kmer.shape} (samples x 64 features)\")\n",
    "# ذخیره موقت برای استفاده در گام‌های بعدی\n",
    "import numpy as np\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_kmer_temp.npy\", X_kmer)\n",
    "print(\"📝 Saved: X_kmer_temp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b457620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Distance-based motifs extracted: (12410, 16) (samples x 16 features)\n",
      "📝 Saved: X_distance_temp.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# بارگذاری k-mer features برای تست\n",
    "X_kmer = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_kmer_temp.npy\")\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "# تعریف الگوهای فاصله‌دار (A..C، G..T و غیره) با فاصله 2\n",
    "bases = ['A', 'C', 'G', 'U']\n",
    "distance = 2\n",
    "motif_features = []\n",
    "\n",
    "for seq in sequences:\n",
    "    seq_features = []\n",
    "    for start, end in product(bases, bases):\n",
    "        pattern = f\"{start}.{{{distance}}}{end}\"\n",
    "        count = sum(1 for i in range(len(seq) - distance - 1) if seq[i] == start and seq[i + distance + 1] == end)\n",
    "        seq_features.append(count)\n",
    "    motif_features.append(seq_features)\n",
    "\n",
    "X_distance = np.array(motif_features)\n",
    "print(f\"✅ Distance-based motifs extracted: {X_distance.shape} (samples x {len(bases) * len(bases)} features)\")\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_distance_temp.npy\", X_distance)\n",
    "print(\"📝 Saved: X_distance_temp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0395ddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CGR features extracted: (12410, 4) (samples x 4 features)\n",
      "📝 Saved: X_cgr_temp.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# بارگذاری داده‌ها\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "def cgr_feature(sequence):\n",
    "    # نقاط اولیه برای A, C, G, U\n",
    "    points = {'A': (0, 0), 'C': (1, 0), 'G': (0, 1), 'U': (1, 1)}\n",
    "    x, y = 0.5, 0.5  # نقطه شروع\n",
    "    for base in sequence:\n",
    "        if base in points:\n",
    "            px, py = points[base]\n",
    "            x = (x + px) / 2\n",
    "            y = (y + py) / 2\n",
    "    # بردار آماری ساده (میانگین و واریانس مختصات)\n",
    "    return [x, y, np.var([x for _ in sequence]), np.var([y for _ in sequence])]\n",
    "\n",
    "# استخراج ویژگی‌ها\n",
    "cgr_features = np.array([cgr_feature(seq) for seq in sequences])\n",
    "print(f\"✅ CGR features extracted: {cgr_features.shape} (samples x 4 features)\")\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_cgr_temp.npy\", cgr_features)\n",
    "print(\"📝 Saved: X_cgr_temp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015737c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PSSM features extracted: (12410, 400) (samples x 400 features)\n",
      "📝 Saved: X_pssm_temp.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# بارگذاری داده‌ها\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "# تنظیم طول ثابت (مثلاً 100، می‌تونی تغییر بدی)\n",
    "max_length = 100\n",
    "\n",
    "def pad_sequence(seq, max_len):\n",
    "    if len(seq) > max_len:\n",
    "        return seq[:max_len]\n",
    "    return seq + 'N' * (max_len - len(seq))\n",
    "\n",
    "# پد کردن توالی‌ها\n",
    "padded_sequences = [pad_sequence(seq, max_length) for seq in sequences]\n",
    "\n",
    "# محاسبه PSSM\n",
    "pssm_features = []\n",
    "for seq in padded_sequences:\n",
    "    pos_counts = np.zeros((max_length, 4))  # برای A, C, G, U\n",
    "    for i, base in enumerate(seq):\n",
    "        if base == 'A': pos_counts[i, 0] += 1\n",
    "        elif base == 'C': pos_counts[i, 1] += 1\n",
    "        elif base == 'G': pos_counts[i, 2] += 1\n",
    "        elif base == 'U': pos_counts[i, 3] += 1\n",
    "    pssm_features.append(pos_counts.flatten())\n",
    "\n",
    "X_pssm = np.array(pssm_features)\n",
    "print(f\"✅ PSSM features extracted: {X_pssm.shape} (samples x {max_length * 4} features)\")\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_pssm_temp.npy\", X_pssm)\n",
    "print(\"📝 Saved: X_pssm_temp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3f1c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SSF features extracted: (12410, 6) (samples x 6 features)\n",
      "📝 Saved: X_ssf_temp.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# بارگذاری داده‌ها\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "def statistical_features(sequence):\n",
    "    total = len(sequence)\n",
    "    a_count = sequence.count('A') / total\n",
    "    c_count = sequence.count('C') / total\n",
    "    g_count = sequence.count('G') / total\n",
    "    u_count = sequence.count('U') / total\n",
    "    gc_content = (g_count + c_count)\n",
    "    # Shannon Entropy\n",
    "    entropy = 0\n",
    "    for base in 'ACGU':\n",
    "        p = sequence.count(base) / total\n",
    "        if p > 0:\n",
    "            entropy -= p * np.log2(p)\n",
    "    return [a_count, c_count, g_count, u_count, gc_content, entropy]\n",
    "\n",
    "# استخراج ویژگی‌ها\n",
    "ssf_features = np.array([statistical_features(seq) for seq in sequences])\n",
    "print(f\"✅ SSF features extracted: {ssf_features.shape} (samples x 6 features)\")\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_ssf_temp.npy\", ssf_features)\n",
    "print(\"📝 Saved: X_ssf_temp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa828790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined features shape: (12410, 490)\n",
      "📝 Saved: X_handcrafted.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# بارگذاری همه ویژگی‌های موقت\n",
    "X_kmer = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_kmer_temp.npy\")\n",
    "X_distance = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_distance_temp.npy\")\n",
    "X_cgr = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_cgr_temp.npy\")\n",
    "X_pssm = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_pssm_temp.npy\")\n",
    "X_ssf = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_ssf_temp.npy\")\n",
    "\n",
    "# ترکیب ویژگی‌ها\n",
    "X_handcrafted = np.concatenate((X_kmer, X_distance, X_cgr, X_pssm, X_ssf), axis=1)\n",
    "print(f\"✅ Combined features shape: {X_handcrafted.shape}\")\n",
    "\n",
    "# نرمال‌سازی\n",
    "scaler = StandardScaler()\n",
    "X_handcrafted_scaled = scaler.fit_transform(X_handcrafted)\n",
    "\n",
    "# ذخیره نهایی\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_handcrafted.npy\", X_handcrafted_scaled)\n",
    "print(\"📝 Saved: X_handcrafted.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99f5f998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERT features extracted: (12410, 768) (samples x 768 features)\n",
      "📝 Saved: X_bert.npy\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# بارگذاری مدل و توکن‌کننده با اسم اصلاح‌شده\n",
    "model_name = \"zhihan1996/DNA_bert_6\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# بارگذاری داده‌ها\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "# استخراج embeddings\n",
    "def get_bert_features(sequence):\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=4000, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "bert_features = np.array([get_bert_features(seq) for seq in sequences])\n",
    "print(f\"✅ BERT features extracted: {bert_features.shape} (samples x 768 features)\")\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_bert.npy\", bert_features)\n",
    "print(\"📝 Saved: X_bert.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ea8b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_handcrafted: (12410, 490)\n",
      "Shape of X_bert: (12410, 768)\n",
      "Number of samples match: 12410\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# بارگذاری فایل‌ها\n",
    "X_handcrafted = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_handcrafted.npy\")\n",
    "X_bert = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_bert.npy\")\n",
    "\n",
    "# چاپ ابعاد\n",
    "print(f\"Shape of X_handcrafted: {X_handcrafted.shape}\")  # [N, F₁]\n",
    "print(f\"Shape of X_bert: {X_bert.shape}\")  # [N, F₂]\n",
    "\n",
    "# برای اطمینان، تعداد نمونه‌ها رو مقایسه کن\n",
    "if X_handcrafted.shape[0] == X_bert.shape[0]:\n",
    "    print(f\"Number of samples match: {X_handcrafted.shape[0]}\")\n",
    "else:\n",
    "    print(\"Warning: Number of samples do not match!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
