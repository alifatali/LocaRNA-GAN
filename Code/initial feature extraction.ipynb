{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfae9982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… k-mer features extracted: (12410, 64) (samples x 64 features)\n",
      "ğŸ“ Saved: X_kmer_temp.npy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "# Ø§Ø³ØªØ®Ø±Ø§Ø¬ k-mer Ø¨Ø§ k=3\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3), lowercase=False)\n",
    "kmer_features = vectorizer.fit_transform(sequences)\n",
    "\n",
    "# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¢Ø±Ø§ÛŒÙ‡ NumPy\n",
    "X_kmer = kmer_features.toarray()\n",
    "\n",
    "print(f\"âœ… k-mer features extracted: {X_kmer.shape} (samples x 64 features)\")\n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ú¯Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ\n",
    "import numpy as np\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_kmer_temp.npy\", X_kmer)\n",
    "print(\"ğŸ“ Saved: X_kmer_temp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b457620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Distance-based motifs extracted: (12410, 16) (samples x 16 features)\n",
      "ğŸ“ Saved: X_distance_temp.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ k-mer features Ø¨Ø±Ø§ÛŒ ØªØ³Øª\n",
    "X_kmer = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_kmer_temp.npy\")\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "# ØªØ¹Ø±ÛŒÙ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÙØ§ØµÙ„Ù‡â€ŒØ¯Ø§Ø± (A..CØŒ G..T Ùˆ ØºÛŒØ±Ù‡) Ø¨Ø§ ÙØ§ØµÙ„Ù‡ 2\n",
    "bases = ['A', 'C', 'G', 'U']\n",
    "distance = 2\n",
    "motif_features = []\n",
    "\n",
    "for seq in sequences:\n",
    "    seq_features = []\n",
    "    for start, end in product(bases, bases):\n",
    "        pattern = f\"{start}.{{{distance}}}{end}\"\n",
    "        count = sum(1 for i in range(len(seq) - distance - 1) if seq[i] == start and seq[i + distance + 1] == end)\n",
    "        seq_features.append(count)\n",
    "    motif_features.append(seq_features)\n",
    "\n",
    "X_distance = np.array(motif_features)\n",
    "print(f\"âœ… Distance-based motifs extracted: {X_distance.shape} (samples x {len(bases) * len(bases)} features)\")\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_distance_temp.npy\", X_distance)\n",
    "print(\"ğŸ“ Saved: X_distance_temp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0395ddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CGR features extracted: (12410, 4) (samples x 4 features)\n",
      "ğŸ“ Saved: X_cgr_temp.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "def cgr_feature(sequence):\n",
    "    # Ù†Ù‚Ø§Ø· Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ A, C, G, U\n",
    "    points = {'A': (0, 0), 'C': (1, 0), 'G': (0, 1), 'U': (1, 1)}\n",
    "    x, y = 0.5, 0.5  # Ù†Ù‚Ø·Ù‡ Ø´Ø±ÙˆØ¹\n",
    "    for base in sequence:\n",
    "        if base in points:\n",
    "            px, py = points[base]\n",
    "            x = (x + px) / 2\n",
    "            y = (y + py) / 2\n",
    "    # Ø¨Ø±Ø¯Ø§Ø± Ø¢Ù…Ø§Ø±ÛŒ Ø³Ø§Ø¯Ù‡ (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ùˆ ÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ù…Ø®ØªØµØ§Øª)\n",
    "    return [x, y, np.var([x for _ in sequence]), np.var([y for _ in sequence])]\n",
    "\n",
    "# Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§\n",
    "cgr_features = np.array([cgr_feature(seq) for seq in sequences])\n",
    "print(f\"âœ… CGR features extracted: {cgr_features.shape} (samples x 4 features)\")\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_cgr_temp.npy\", cgr_features)\n",
    "print(\"ğŸ“ Saved: X_cgr_temp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015737c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PSSM features extracted: (12410, 400) (samples x 400 features)\n",
      "ğŸ“ Saved: X_pssm_temp.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "# ØªÙ†Ø¸ÛŒÙ… Ø·ÙˆÙ„ Ø«Ø§Ø¨Øª (Ù…Ø«Ù„Ø§Ù‹ 100ØŒ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ ØªØºÛŒÛŒØ± Ø¨Ø¯ÛŒ)\n",
    "max_length = 100\n",
    "\n",
    "def pad_sequence(seq, max_len):\n",
    "    if len(seq) > max_len:\n",
    "        return seq[:max_len]\n",
    "    return seq + 'N' * (max_len - len(seq))\n",
    "\n",
    "# Ù¾Ø¯ Ú©Ø±Ø¯Ù† ØªÙˆØ§Ù„ÛŒâ€ŒÙ‡Ø§\n",
    "padded_sequences = [pad_sequence(seq, max_length) for seq in sequences]\n",
    "\n",
    "# Ù…Ø­Ø§Ø³Ø¨Ù‡ PSSM\n",
    "pssm_features = []\n",
    "for seq in padded_sequences:\n",
    "    pos_counts = np.zeros((max_length, 4))  # Ø¨Ø±Ø§ÛŒ A, C, G, U\n",
    "    for i, base in enumerate(seq):\n",
    "        if base == 'A': pos_counts[i, 0] += 1\n",
    "        elif base == 'C': pos_counts[i, 1] += 1\n",
    "        elif base == 'G': pos_counts[i, 2] += 1\n",
    "        elif base == 'U': pos_counts[i, 3] += 1\n",
    "    pssm_features.append(pos_counts.flatten())\n",
    "\n",
    "X_pssm = np.array(pssm_features)\n",
    "print(f\"âœ… PSSM features extracted: {X_pssm.shape} (samples x {max_length * 4} features)\")\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_pssm_temp.npy\", X_pssm)\n",
    "print(\"ğŸ“ Saved: X_pssm_temp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3f1c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SSF features extracted: (12410, 6) (samples x 6 features)\n",
      "ğŸ“ Saved: X_ssf_temp.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "def statistical_features(sequence):\n",
    "    total = len(sequence)\n",
    "    a_count = sequence.count('A') / total\n",
    "    c_count = sequence.count('C') / total\n",
    "    g_count = sequence.count('G') / total\n",
    "    u_count = sequence.count('U') / total\n",
    "    gc_content = (g_count + c_count)\n",
    "    # Shannon Entropy\n",
    "    entropy = 0\n",
    "    for base in 'ACGU':\n",
    "        p = sequence.count(base) / total\n",
    "        if p > 0:\n",
    "            entropy -= p * np.log2(p)\n",
    "    return [a_count, c_count, g_count, u_count, gc_content, entropy]\n",
    "\n",
    "# Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§\n",
    "ssf_features = np.array([statistical_features(seq) for seq in sequences])\n",
    "print(f\"âœ… SSF features extracted: {ssf_features.shape} (samples x 6 features)\")\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_ssf_temp.npy\", ssf_features)\n",
    "print(\"ğŸ“ Saved: X_ssf_temp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa828790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Combined features shape: (12410, 490)\n",
      "ğŸ“ Saved: X_handcrafted.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‡Ù…Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª\n",
    "X_kmer = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_kmer_temp.npy\")\n",
    "X_distance = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_distance_temp.npy\")\n",
    "X_cgr = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_cgr_temp.npy\")\n",
    "X_pssm = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_pssm_temp.npy\")\n",
    "X_ssf = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_ssf_temp.npy\")\n",
    "\n",
    "# ØªØ±Ú©ÛŒØ¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§\n",
    "X_handcrafted = np.concatenate((X_kmer, X_distance, X_cgr, X_pssm, X_ssf), axis=1)\n",
    "print(f\"âœ… Combined features shape: {X_handcrafted.shape}\")\n",
    "\n",
    "# Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ\n",
    "scaler = StandardScaler()\n",
    "X_handcrafted_scaled = scaler.fit_transform(X_handcrafted)\n",
    "\n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_handcrafted.npy\", X_handcrafted_scaled)\n",
    "print(\"ğŸ“ Saved: X_handcrafted.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99f5f998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BERT features extracted: (12410, 768) (samples x 768 features)\n",
      "ğŸ“ Saved: X_bert.npy\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ ØªÙˆÚ©Ù†â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¨Ø§ Ø§Ø³Ù… Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡\n",
    "model_name = \"zhihan1996/DNA_bert_6\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "df_rnalocate = pd.read_csv(\"F:/payan-nameh/faz2 . 1404.04.02/rnalocate_dataset.csv\")\n",
    "sequences = df_rnalocate['sequence'].values\n",
    "\n",
    "# Ø§Ø³ØªØ®Ø±Ø§Ø¬ embeddings\n",
    "def get_bert_features(sequence):\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=4000, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "bert_features = np.array([get_bert_features(seq) for seq in sequences])\n",
    "print(f\"âœ… BERT features extracted: {bert_features.shape} (samples x 768 features)\")\n",
    "np.save(\"F:/payan-nameh/faz2 . 1404.04.02/X_bert.npy\", bert_features)\n",
    "print(\"ğŸ“ Saved: X_bert.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ea8b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_handcrafted: (12410, 490)\n",
      "Shape of X_bert: (12410, 768)\n",
      "Number of samples match: 12410\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§\n",
    "X_handcrafted = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_handcrafted.npy\")\n",
    "X_bert = np.load(\"F:/payan-nameh/faz2 . 1404.04.02/X_bert.npy\")\n",
    "\n",
    "# Ú†Ø§Ù¾ Ø§Ø¨Ø¹Ø§Ø¯\n",
    "print(f\"Shape of X_handcrafted: {X_handcrafted.shape}\")  # [N, Fâ‚]\n",
    "print(f\"Shape of X_bert: {X_bert.shape}\")  # [N, Fâ‚‚]\n",
    "\n",
    "# Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†ØŒ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ Ø±Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ù†\n",
    "if X_handcrafted.shape[0] == X_bert.shape[0]:\n",
    "    print(f\"Number of samples match: {X_handcrafted.shape[0]}\")\n",
    "else:\n",
    "    print(\"Warning: Number of samples do not match!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
