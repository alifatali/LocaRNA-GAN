{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ffb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200, Loss: 0.2766, Acc: 0.8915, Prec: 0.8893, Recall: 0.8919, F1: 0.8895\n",
      "Epoch 185/200, Loss: 0.2841, Acc: 0.8896, Prec: 0.8859, Recall: 0.8889, F1: 0.8864\n",
      "Epoch 186/200, Loss: 0.2718, Acc: 0.8947, Prec: 0.8910, Recall: 0.8930, F1: 0.8910\n",
      "Epoch 187/200, Loss: 0.2766, Acc: 0.8926, Prec: 0.8890, Recall: 0.8917, F1: 0.8893\n",
      "Epoch 188/200, Loss: 0.2885, Acc: 0.8899, Prec: 0.8881, Recall: 0.8911, F1: 0.8886\n",
      "Epoch 189/200, Loss: 0.2833, Acc: 0.8890, Prec: 0.8857, Recall: 0.8888, F1: 0.8862\n",
      "Epoch 190/200, Loss: 0.2694, Acc: 0.8932, Prec: 0.8909, Recall: 0.8930, F1: 0.8911\n",
      "Epoch 191/200, Loss: 0.2772, Acc: 0.8901, Prec: 0.8872, Recall: 0.8906, F1: 0.8878\n",
      "Epoch 192/200, Loss: 0.2860, Acc: 0.8867, Prec: 0.8834, Recall: 0.8868, F1: 0.8841\n",
      "Epoch 193/200, Loss: 0.2658, Acc: 0.8917, Prec: 0.8893, Recall: 0.8923, F1: 0.8898\n",
      "Epoch 194/200, Loss: 0.2791, Acc: 0.8907, Prec: 0.8880, Recall: 0.8910, F1: 0.8886\n",
      "Epoch 195/200, Loss: 0.2766, Acc: 0.8908, Prec: 0.8890, Recall: 0.8924, F1: 0.8895\n",
      "Epoch 196/200, Loss: 0.2814, Acc: 0.8877, Prec: 0.8840, Recall: 0.8865, F1: 0.8843\n",
      "Epoch 197/200, Loss: 0.2719, Acc: 0.8927, Prec: 0.8892, Recall: 0.8916, F1: 0.8895\n",
      "Epoch 198/200, Loss: 0.2779, Acc: 0.8927, Prec: 0.8914, Recall: 0.8952, F1: 0.8923\n",
      "Epoch 199/200, Loss: 0.2745, Acc: 0.8898, Prec: 0.8867, Recall: 0.8894, F1: 0.8870\n",
      "Epoch 200/200, Loss: 0.2633, Acc: 0.8961, Prec: 0.8928, Recall: 0.8949, F1: 0.8930\n",
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7900    0.7352    0.7616      2477\n",
      "           1     0.8368    0.7771    0.8058      2414\n",
      "           2     0.9976    0.9988    0.9982      2485\n",
      "           3     0.8922    0.9752    0.9319      2503\n",
      "           4     0.9477    0.9881    0.9675      2531\n",
      "\n",
      "    accuracy                         0.8961     12410\n",
      "   macro avg     0.8928    0.8949    0.8930     12410\n",
      "weighted avg     0.8934    0.8961    0.8939     12410\n",
      "\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# چک دسترسی GPU\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU available, using CPU. Consider installing PyTorch with CUDA support.\")\n",
    "\n",
    "# تعریف دیتاست\n",
    "class RNADataset(Dataset):\n",
    "    def __init__(self, X_handcrafted, X_bert, labels):\n",
    "        self.X_handcrafted = torch.FloatTensor(X_handcrafted)\n",
    "        self.X_bert = torch.FloatTensor(X_bert)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_handcrafted[idx], self.X_bert[idx], self.labels[idx]\n",
    "\n",
    "# معماری مدل\n",
    "class DualAttentionModel(nn.Module):\n",
    "    def __init__(self, input_dim_hand=490, input_dim_bert=768, d_model=256, num_classes=5):\n",
    "        super(DualAttentionModel, self).__init__()\n",
    "        \n",
    "        self.hand_fc = nn.Linear(input_dim_hand, d_model)\n",
    "        self.hand_attn = nn.MultiheadAttention(d_model, num_heads=4, batch_first=True)\n",
    "        self.hand_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.bert_fc = nn.Linear(input_dim_bert, d_model)\n",
    "        self.bert_attn = nn.MultiheadAttention(d_model, num_heads=4, batch_first=True)\n",
    "        self.bert_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.fusion = nn.Linear(d_model * 2, d_model)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_hand, x_bert):\n",
    "        x_hand = self.hand_fc(x_hand)\n",
    "        x_hand = x_hand.unsqueeze(1)\n",
    "        x_hand, _ = self.hand_attn(x_hand, x_hand, x_hand)\n",
    "        x_hand = x_hand.squeeze(1)\n",
    "\n",
    "        x_bert = self.bert_fc(x_bert)\n",
    "        x_bert = x_bert.unsqueeze(1)\n",
    "        x_bert, _ = self.bert_attn(x_bert, x_bert, x_bert)\n",
    "        x_bert = x_bert.squeeze(1)\n",
    "\n",
    "        fusion = torch.cat([x_hand, x_bert], dim=-1)\n",
    "        fusion = self.fusion(fusion)\n",
    "\n",
    "        out = self.classifier(fusion)\n",
    "        return out\n",
    "\n",
    "# بارگذاری داده‌ها\n",
    "X_handcrafted = np.load(\"F:\\\\payan-nameh\\\\faz2 . 1404.04.02\\\\Date\\\\RNALocate\\\\X_handcrafted.npy\")\n",
    "X_bert = np.load(\"F:\\\\payan-nameh\\\\faz2 . 1404.04.02\\\\Date\\\\RNALocate\\\\X_bert.npy\")\n",
    "df_rnalocate = pd.read_csv(\"F:\\\\payan-nameh\\\\faz2 . 1404.04.02\\\\Date\\\\RNALocate\\\\rnalocate_dataset.csv\")\n",
    "labels = df_rnalocate['label'].values\n",
    "\n",
    "# تنظیم وزن برای تعادل داده‌ها\n",
    "class_counts = np.bincount(labels)\n",
    "num_samples = len(labels)\n",
    "weights = 1.0 / class_counts[labels]\n",
    "sampler = WeightedRandomSampler(weights, num_samples, replacement=True)\n",
    "\n",
    "# ساخت دیتالودر\n",
    "dataset = RNADataset(X_handcrafted, X_bert, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, sampler=sampler)\n",
    "\n",
    "# تعریف مدل، لاس و بهینه‌ساز\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DualAttentionModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# لیست‌ها برای ذخیره معیارها\n",
    "epoch_losses = []\n",
    "epoch_accs = []\n",
    "epoch_precisions = []\n",
    "epoch_recalls = []\n",
    "epoch_f1s = []\n",
    "\n",
    "# حلقه آموزش\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for x_hand, x_bert, y in dataloader:\n",
    "        x_hand, x_bert, y = x_hand.to(device), x_bert.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(x_hand, x_bert)\n",
    "            loss = criterion(outputs, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "    epoch_losses.append(avg_loss)\n",
    "    epoch_accs.append(acc)\n",
    "    epoch_precisions.append(precision.mean())  # میانگین Precision برای هر کلاس\n",
    "    epoch_recalls.append(recall.mean())       # میانگین Recall برای هر کلاس\n",
    "    epoch_f1s.append(f1.mean())               # میانگین F1 برای هر کلاس\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Acc: {acc:.4f}, Prec: {precision.mean():.4f}, Recall: {recall.mean():.4f}, F1: {f1.mean():.4f}\")\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "# محاسبه و چاپ Precision, Recall, F1-Score نهایی\n",
    "final_report = classification_report(all_labels, all_preds, digits=4)\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(final_report)\n",
    "\n",
    "# محاسبه و رسم ماتریس درهم‌ریختگی\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(5), yticklabels=range(5))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"F:\\\\payan-nameh\\\\faz2 . 1404.04.02\\\\Date\\\\RNALocate\\\\confusion_matrix2.png\")\n",
    "plt.close()\n",
    "\n",
    "# رسم و ذخیره نمودار Precision, Recall, F1\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, num_epochs + 1), epoch_precisions, label='Precision', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(1, num_epochs + 1), epoch_recalls, label='Recall', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(1, num_epochs + 1), epoch_f1s, label='F1-Score', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('F1-Score Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"F:\\\\payan-nameh\\\\faz2 . 1404.04.02\\\\Date\\\\RNALocate\\\\prf_metrics2.png\")\n",
    "plt.close()\n",
    "\n",
    "# ذخیره مدل\n",
    "torch.save(model.state_dict(), \"F:\\\\payan-nameh\\\\faz2 . 1404.04.02\\\\Date\\\\RNALocate\\\\dual_attention_model2.pth\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# رسم و ذخیره نمودار Loss و Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), epoch_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), epoch_accs, label='Training Accuracy', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"F:\\\\payan-nameh\\\\faz2 . 1404.04.02\\\\Date\\\\RNALocate\\\\training_metrics2.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441e39ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد نمونه‌ها در هر کلاس:\n",
      "کلاس 0: 5310 نمونه\n",
      "کلاس 1: 4855 نمونه\n",
      "کلاس 2: 350 نمونه\n",
      "کلاس 3: 1185 نمونه\n",
      "کلاس 4: 710 نمونه\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# لود داده‌ها\n",
    "X_handcrafted = np.load(\"F:\\\\payan-nameh\\\\faz2 . 1404.04.02\\\\Date\\\\RNALocate\\\\X_handcrafted.npy\")\n",
    "X_bert = np.load(\"F:\\\\payan-nameh\\\\faz2 . 1404.04.02\\\\Date\\\\RNALocate\\\\X_bert.npy\")\n",
    "df_rnalocate = pd.read_csv(\"F:\\\\payan-nameh\\\\faz2 . 1404.04.02\\\\Date\\\\RNALocate\\\\rnalocate_dataset.csv\")\n",
    "labels = df_rnalocate['label'].values\n",
    "\n",
    "# شمارش تعداد نمونه‌ها در هر کلاس\n",
    "class_counts = np.bincount(labels)\n",
    "num_classes = len(class_counts)\n",
    "\n",
    "# چاپ نتایج\n",
    "print(\"تعداد نمونه‌ها در هر کلاس:\")\n",
    "for i in range(num_classes):\n",
    "    count = class_counts[i] if i < len(class_counts) else 0\n",
    "    print(f\"کلاس {i}: {count} نمونه\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
